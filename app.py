# app.pyï¼ˆä¸­æ–‡ç•Œé¢ï¼‰
import json
import base64
import csv
import io
import re
from datetime import datetime
from typing import List, Dict, Tuple, Any

import streamlit as st

# =========================
# æ ¸å¿ƒé€»è¾‘ï¼ˆä¿ç•™ä½ çš„è§£ææµç¨‹ï¼‰
# =========================

def decode_content(content):
    """å°è¯•ç”¨å¤šç§æ–¹å¼è§£ç å“åº”æ–‡æœ¬ä¸º JSONã€‚"""
    if not content:
        return None

    if isinstance(content, str):
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            content = content.strip()
            if content.startswith('{') and content.endswith('}'):
                try:
                    return json.loads(content)
                except json.JSONDecodeError:
                    pass

    encodings = ['utf-8', 'latin1', 'cp1252', 'ascii']

    if isinstance(content, str):
        try:
            decoded = base64.b64decode(content, validate=False)
            for encoding in encodings:
                try:
                    text = decoded.decode(encoding, errors='strict')
                    try:
                        return json.loads(text)
                    except json.JSONDecodeError:
                        pass
                except UnicodeDecodeError:
                    continue
        except Exception:
            pass

    if isinstance(content, (bytes, bytearray)):
        for encoding in encodings:
            try:
                text = content.decode(encoding)
                try:
                    return json.loads(text)
                except json.JSONDecodeError:
                    pass
            except UnicodeDecodeError:
                continue

    return None


def extract_orders(data: Dict[str, Any]) -> Tuple[List[Dict[str, Any]], Dict[str, int]]:
    """ä»æ¥å£å“åº”ä¸­æå–è®¢å•ä¿¡æ¯ã€‚"""
    orders = []
    phone_sources = {'recharge_data': 0, 'buyer_phone': 0, 'nickname': 0}

    try:
        if not isinstance(data, dict):
            return orders, phone_sources
        if data.get('code') != 0:
            return orders, phone_sources

        order_list = data.get('orderList', [])
        for order in order_list:
            if not isinstance(order, dict):
                continue

            buyer_info = order.get('buyerInfo', {})
            common_info = order.get('commonInfo', {})

            # æŒ‰ä¼˜å…ˆçº§æå–æ‰‹æœºå·
            phone = ''
            accept_info = order.get('acceptInfo', {})
            recharge_data = accept_info.get('rechargeData', {})
            content = recharge_data.get('content', '')
            if content:
                match = re.search(r'(1[3-9]\d{9})', content)
                if match:
                    phone = match.group(1)
                    phone_sources['recharge_data'] += 1

            if not phone:
                phone = buyer_info.get('phone', '')
                if phone:
                    phone_sources['buyer_phone'] += 1

            if not phone:
                nick = buyer_info.get('nickName', '')
                match = re.search(r'(1[3-9]\d{9})', nick)
                if match:
                    phone = match.group(1)
                    phone_sources['nickname'] += 1

            order_data = {
                'Order ID': common_info.get('orderId', ''),
                'Buyer Nickname': buyer_info.get('nickName', ''),
                'Status': common_info.get('statusStr', ''),
                'æ‰‹æœºå·': phone
            }
            orders.append(order_data)

    except Exception:
        pass

    return orders, phone_sources


def extract_data(har_data: Dict[str, Any]) -> Tuple[List[Dict[str, Any]], Dict[str, int]]:
    """ä» HAR æ–‡ä»¶çš„ entries ä¸­æå–è®¢å•æ•°æ®ã€‚"""
    extracted_data: List[Dict[str, Any]] = []
    total_phone_sources = {'recharge_data': 0, 'buyer_phone': 0, 'nickname': 0}

    if not har_data or 'log' not in har_data or 'entries' not in har_data['log']:
        return extracted_data, total_phone_sources

    entries = har_data['log']['entries']
    for entry in entries:
        try:
            request = entry.get('request', {})
            url = request.get('url', '')
            if 'orderSearch' not in url:
                continue

            response = entry.get('response', {})
            content = response.get('content', {})
            if not content or not content.get('text'):
                continue

            mime_type = content.get('mimeType', 'unknown')
            if not isinstance(mime_type, str) or not mime_type.lower().startswith('application/json'):
                continue

            data = decode_content(content.get('text', ''))
            if not data:
                continue

            orders, phone_sources = extract_orders(data)
            if orders:
                extracted_data.extend(orders)
                for k, v in phone_sources.items():
                    total_phone_sources[k] += v

        except Exception:
            continue

    return extracted_data, total_phone_sources


def har_bytes_to_json(b: bytes):
    """å°† HARï¼ˆäºŒè¿›åˆ¶ï¼‰è§£æä¸º JSONã€‚"""
    for enc in ('utf-8', 'utf-16', 'latin1'):
        try:
            return json.loads(b.decode(enc))
        except Exception:
            continue
    try:
        return json.loads(b)
    except Exception:
        return None


def to_csv_bytes(rows: List[Dict[str, Any]]) -> bytes:
    """å°†ç»“æœè¡Œå†™æˆ CSVï¼ˆäºŒè¿›åˆ¶ï¼ŒUTF-8-SIGï¼‰ã€‚"""
    if not rows:
        return b''

    safe_rows = []
    for r in rows:
        r = dict(r)
        # ä¸ºé¿å… Excel å°†é•¿è®¢å•å·è½¬ç§‘å­¦è®¡æ•°æ³•ï¼Œå‰ç½®é›¶å®½ç©ºæ ¼
        r['Order ID'] = '\u200B' + str(r.get('Order ID', ''))
        safe_rows.append(r)

    field_order = ['Order ID', 'Buyer Nickname', 'Status', 'æ‰‹æœºå·']
    buf = io.StringIO()
    writer = csv.DictWriter(buf, fieldnames=field_order, quoting=csv.QUOTE_ALL)
    writer.writeheader()
    writer.writerows(safe_rows)
    return buf.getvalue().encode('utf-8-sig')


# =========================
# Streamlit ç•Œé¢ï¼ˆä¸­æ–‡ï¼‰
# =========================

st.set_page_config(page_title="HAR è½¬ CSV", page_icon="ğŸ“¦", layout="centered")
st.title("ğŸ“¦ HAR è½¬ CSV")
st.markdown(
    "ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ª `.har` æ–‡ä»¶ï¼ˆä»æµè§ˆå™¨å¼€å‘è€…å·¥å…·çš„ **Network** é¢æ¿å¯¼å‡ºï¼‰ã€‚"
    "åº”ç”¨ä¼šæ‰«æåŒ…å« `orderSearch` çš„å“åº”ï¼Œæå–è®¢å•å¹¶åˆå¹¶ä¸ºä¸€ä»½ CSVã€‚"
)

uploaded = st.file_uploader(
    "æ‹–æ‹½æˆ–é€‰æ‹© `.har` æ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼‰",
    type=["har"],
    accept_multiple_files=True,
    help="Chrome/Edgeï¼šæ‰“å¼€å¼€å‘è€…å·¥å…· â†’ Network â†’ å³é”®ç©ºç™½å¤„ â†’ Save all as HAR with contentã€‚"
)

run_btn = st.button("å¼€å§‹å¤„ç†")

if run_btn:
    if not uploaded:
        st.warning("è¯·è‡³å°‘ä¸Šä¼  1 ä¸ª `.har` æ–‡ä»¶ã€‚")
        st.stop()

    all_rows: List[Dict[str, Any]] = []
    progress = st.progress(0)

    for i, uf in enumerate(uploaded, start=1):
        with st.status(f"æ­£åœ¨å¤„ç† **{uf.name}** â€¦", expanded=False):
            raw = uf.read()
            har_obj = har_bytes_to_json(raw)
            if not har_obj:
                st.error(f"æ— æ³•è§£æ HARï¼š{uf.name}")
            else:
                rows, _ = extract_data(har_obj)
                all_rows.extend(rows)
                st.write(f"åœ¨è¯¥æ–‡ä»¶ä¸­å‘ç° **{len(rows)}** æ¡è®¢å•ã€‚")

        progress.progress(i / len(uploaded))

    if not all_rows:
        st.info("æœªåœ¨æ‰€ä¸Šä¼ çš„æ–‡ä»¶ä¸­æ‰¾åˆ°è®¢å•æ•°æ®ã€‚")
        st.stop()

    # å¯¼å‡º CSV
    csv_bytes = to_csv_bytes(all_rows)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    out_name = f"orders_{ts}.csv"

    st.success(f"å®Œæˆï¼å…±ä» **{len(uploaded)}** ä¸ªæ–‡ä»¶æå– **{len(all_rows)}** æ¡è®¢å•ã€‚")
    st.download_button("â¬‡ï¸ ä¸‹è½½åˆå¹¶åçš„ CSV", data=csv_bytes, file_name=out_name, mime="text/csv")

    # å¯é…ç½®çš„é¢„è§ˆåŒºï¼ˆä¸å†æ˜¾ç¤ºâ€œæ‰‹æœºå·æ¥æºç»Ÿè®¡â€ï¼‰
    with st.expander("é¢„è§ˆæ•°æ®ï¼ˆå‰ N è¡Œï¼‰"):
        max_n = len(all_rows)
        default_n = min(1000, max_n)
        n = st.number_input("é€‰æ‹©è¦é¢„è§ˆçš„è¡Œæ•°ï¼ˆä» 1 å¼€å§‹ï¼‰", min_value=1, max_value=max_n, value=default_n, step=100)
        st.dataframe(all_rows[:n], use_container_width=True)

